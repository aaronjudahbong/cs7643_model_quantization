Model Size: 10.57 MB

mIoU: 0.5789

Per-Class IoU:
  Class 0: 0.9570
  Class 1: 0.7094
  Class 2: 0.8565
  Class 3: 0.3360
  Class 4: 0.4539
  Class 5: 0.2725
  Class 6: 0.4575
  Class 7: 0.5289
  Class 8: 0.8695
  Class 9: 0.5419
  Class 10: 0.8754
  Class 11: 0.6112
  Class 12: 0.4157
  Class 13: 0.8610
  Class 14: 0.4424
  Class 15: 0.5857
  Class 16: 0.2672
  Class 17: 0.3637
  Class 18: 0.5934

Training Losses:
  Epoch 1: 0.372000
  Epoch 2: 0.310982
  Epoch 3: 0.285639
  Epoch 4: 0.241414
  Epoch 5: 0.210234

Validation Losses:
  Epoch 1: 0.335672
  Epoch 2: 0.511809
  Epoch 3: 0.315458
  Epoch 4: 0.274149
  Epoch 5: 0.242905

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.5476

Per-Class IoU:
  Class 0: 0.9542
  Class 1: 0.6937
  Class 2: 0.8512
  Class 3: 0.2475
  Class 4: 0.4075
  Class 5: 0.2559
  Class 6: 0.4268
  Class 7: 0.5195
  Class 8: 0.8607
  Class 9: 0.4946
  Class 10: 0.8756
  Class 11: 0.6056
  Class 12: 0.3945
  Class 13: 0.8526
  Class 14: 0.4244
  Class 15: 0.5281
  Class 16: 0.1337
  Class 17: 0.2990
  Class 18: 0.5789

Training Losses:
  Epoch 1: 0.396987
  Epoch 2: 0.333643
  Epoch 3: 0.330101
  Epoch 4: 0.269141
  Epoch 5: 0.228650

Validation Losses:
  Epoch 1: 0.358211
  Epoch 2: 0.361618
  Epoch 3: 0.345302
  Epoch 4: 0.296206
  Epoch 5: 0.261598

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6198

Per-Class IoU:
  Class 0: 0.9591
  Class 1: 0.7235
  Class 2: 0.8673
  Class 3: 0.4360
  Class 4: 0.4884
  Class 5: 0.2994
  Class 6: 0.4693
  Class 7: 0.5522
  Class 8: 0.8728
  Class 9: 0.5491
  Class 10: 0.8818
  Class 11: 0.6331
  Class 12: 0.4321
  Class 13: 0.8670
  Class 14: 0.6303
  Class 15: 0.6813
  Class 16: 0.4193
  Class 17: 0.4040
  Class 18: 0.6108

Training Losses:
  Epoch 1: 0.190700
  Epoch 2: 0.189885
  Epoch 3: 0.185133
  Epoch 4: 0.176632
  Epoch 5: 0.171795

Validation Losses:
  Epoch 1: 0.233594
  Epoch 2: 0.230059
  Epoch 3: 0.227277
  Epoch 4: 0.224445
  Epoch 5: 0.226580

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.0001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6189

Per-Class IoU:
  Class 0: 0.9588
  Class 1: 0.7220
  Class 2: 0.8671
  Class 3: 0.4362
  Class 4: 0.4831
  Class 5: 0.2986
  Class 6: 0.4672
  Class 7: 0.5520
  Class 8: 0.8727
  Class 9: 0.5485
  Class 10: 0.8807
  Class 11: 0.6336
  Class 12: 0.4320
  Class 13: 0.8673
  Class 14: 0.6335
  Class 15: 0.6808
  Class 16: 0.4149
  Class 17: 0.4000
  Class 18: 0.6109

Training Losses:
  Epoch 1: 0.191646
  Epoch 2: 0.191826
  Epoch 3: 0.187721
  Epoch 4: 0.179249
  Epoch 5: 0.173725

Validation Losses:
  Epoch 1: 0.232752
  Epoch 2: 0.230095
  Epoch 3: 0.230232
  Epoch 4: 0.225554
  Epoch 5: 0.226934

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.0001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6095

Per-Class IoU:
  Class 0: 0.9580
  Class 1: 0.7149
  Class 2: 0.8635
  Class 3: 0.3906
  Class 4: 0.4658
  Class 5: 0.2886
  Class 6: 0.4654
  Class 7: 0.5455
  Class 8: 0.8729
  Class 9: 0.5495
  Class 10: 0.8810
  Class 11: 0.6227
  Class 12: 0.4373
  Class 13: 0.8639
  Class 14: 0.6057
  Class 15: 0.6669
  Class 16: 0.3764
  Class 17: 0.4062
  Class 18: 0.6059

Training Losses:
  Epoch 1: 0.279794
  Epoch 2: 0.254577
  Epoch 3: 0.230803
  Epoch 4: 0.213778
  Epoch 5: 0.189248

Validation Losses:
  Epoch 1: 0.260523
  Epoch 2: 0.261365
  Epoch 3: 0.413172
  Epoch 4: 0.249159
  Epoch 5: 0.233534

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.0005
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.5968

Per-Class IoU:
  Class 0: 0.9568
  Class 1: 0.7133
  Class 2: 0.8610
  Class 3: 0.3731
  Class 4: 0.4514
  Class 5: 0.2772
  Class 6: 0.4511
  Class 7: 0.5451
  Class 8: 0.8722
  Class 9: 0.5416
  Class 10: 0.8790
  Class 11: 0.6234
  Class 12: 0.4218
  Class 13: 0.8620
  Class 14: 0.5630
  Class 15: 0.6614
  Class 16: 0.3184
  Class 17: 0.3656
  Class 18: 0.6012

Training Losses:
  Epoch 1: 0.287950
  Epoch 2: 0.268244
  Epoch 3: 0.257028
  Epoch 4: 0.224480
  Epoch 5: 0.200724

Validation Losses:
  Epoch 1: 0.270965
  Epoch 2: 0.325308
  Epoch 3: 0.295167
  Epoch 4: 0.278435
  Epoch 5: 0.236744

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.0005
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.5990

Per-Class IoU:
  Class 0: 0.9563
  Class 1: 0.7093
  Class 2: 0.8595
  Class 3: 0.3242
  Class 4: 0.4767
  Class 5: 0.3028
  Class 6: 0.4572
  Class 7: 0.5399
  Class 8: 0.8687
  Class 9: 0.5311
  Class 10: 0.8486
  Class 11: 0.6267
  Class 12: 0.4402
  Class 13: 0.8580
  Class 14: 0.5462
  Class 15: 0.6373
  Class 16: 0.4278
  Class 17: 0.3665
  Class 18: 0.6038

Training Losses:
  Epoch 1: 0.307537
  Epoch 2: 0.269714
  Epoch 3: 0.234271
  Epoch 4: 0.220300
  Epoch 5: 0.194594

Validation Losses:
  Epoch 1: 0.308014
  Epoch 2: 0.306219
  Epoch 3: 0.354610
  Epoch 4: 0.240219
  Epoch 5: 0.239666

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.5886

Per-Class IoU:
  Class 0: 0.9561
  Class 1: 0.7039
  Class 2: 0.8584
  Class 3: 0.2711
  Class 4: 0.4680
  Class 5: 0.2859
  Class 6: 0.4418
  Class 7: 0.5244
  Class 8: 0.8667
  Class 9: 0.5279
  Class 10: 0.8771
  Class 11: 0.6246
  Class 12: 0.4293
  Class 13: 0.8570
  Class 14: 0.5562
  Class 15: 0.6210
  Class 16: 0.3741
  Class 17: 0.3410
  Class 18: 0.5985

Training Losses:
  Epoch 1: 0.318677
  Epoch 2: 0.299879
  Epoch 3: 0.265600
  Epoch 4: 0.239628
  Epoch 5: 0.209777

Validation Losses:
  Epoch 1: 0.316513
  Epoch 2: 0.324697
  Epoch 3: 0.352329
  Epoch 4: 0.257345
  Epoch 5: 0.239433

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6280

Per-Class IoU:
  Class 0: 0.9578
  Class 1: 0.7159
  Class 2: 0.8682
  Class 3: 0.4503
  Class 4: 0.4971
  Class 5: 0.3030
  Class 6: 0.4697
  Class 7: 0.5536
  Class 8: 0.8711
  Class 9: 0.5437
  Class 10: 0.8874
  Class 11: 0.6341
  Class 12: 0.4351
  Class 13: 0.8649
  Class 14: 0.6506
  Class 15: 0.6918
  Class 16: 0.5087
  Class 17: 0.4221
  Class 18: 0.6072

Training Losses:
  Epoch 1: 0.176067
  Epoch 2: 0.178925
  Epoch 3: 0.169333
  Epoch 4: 0.166668
  Epoch 5: 0.165722

Validation Losses:
  Epoch 1: 0.233456
  Epoch 2: 0.225800
  Epoch 3: 0.221923
  Epoch 4: 0.225160
  Epoch 5: 0.227659

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.0001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6277

Per-Class IoU:
  Class 0: 0.9578
  Class 1: 0.7155
  Class 2: 0.8686
  Class 3: 0.4519
  Class 4: 0.4984
  Class 5: 0.3043
  Class 6: 0.4677
  Class 7: 0.5529
  Class 8: 0.8714
  Class 9: 0.5428
  Class 10: 0.8875
  Class 11: 0.6353
  Class 12: 0.4357
  Class 13: 0.8657
  Class 14: 0.6583
  Class 15: 0.6888
  Class 16: 0.4953
  Class 17: 0.4208
  Class 18: 0.6076

Training Losses:
  Epoch 1: 0.176579
  Epoch 2: 0.180496
  Epoch 3: 0.170884
  Epoch 4: 0.168535
  Epoch 5: 0.167365

Validation Losses:
  Epoch 1: 0.231391
  Epoch 2: 0.224433
  Epoch 3: 0.220731
  Epoch 4: 0.223998
  Epoch 5: 0.226713

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.0001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6262

Per-Class IoU:
  Class 0: 0.9569
  Class 1: 0.7128
  Class 2: 0.8688
  Class 3: 0.4663
  Class 4: 0.4922
  Class 5: 0.3001
  Class 6: 0.4641
  Class 7: 0.5408
  Class 8: 0.8701
  Class 9: 0.5314
  Class 10: 0.8874
  Class 11: 0.6314
  Class 12: 0.4365
  Class 13: 0.8648
  Class 14: 0.6266
  Class 15: 0.6797
  Class 16: 0.5293
  Class 17: 0.4308
  Class 18: 0.6077

Training Losses:
  Epoch 1: 0.232658
  Epoch 2: 0.231141
  Epoch 3: 0.200530
  Epoch 4: 0.194209
  Epoch 5: 0.178884

Validation Losses:
  Epoch 1: 0.274969
  Epoch 2: 0.262263
  Epoch 3: 0.256083
  Epoch 4: 0.230848
  Epoch 5: 0.230093

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.0005
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

