Model Size: 10.57 MB

mIoU: 0.5789

Per-Class IoU:
  Class 0: 0.9570
  Class 1: 0.7094
  Class 2: 0.8565
  Class 3: 0.3360
  Class 4: 0.4539
  Class 5: 0.2725
  Class 6: 0.4575
  Class 7: 0.5289
  Class 8: 0.8695
  Class 9: 0.5419
  Class 10: 0.8754
  Class 11: 0.6112
  Class 12: 0.4157
  Class 13: 0.8610
  Class 14: 0.4424
  Class 15: 0.5857
  Class 16: 0.2672
  Class 17: 0.3637
  Class 18: 0.5934

Training Losses:
  Epoch 1: 0.372000
  Epoch 2: 0.310982
  Epoch 3: 0.285639
  Epoch 4: 0.241414
  Epoch 5: 0.210234

Validation Losses:
  Epoch 1: 0.335672
  Epoch 2: 0.511809
  Epoch 3: 0.315458
  Epoch 4: 0.274149
  Epoch 5: 0.242905

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.5476

Per-Class IoU:
  Class 0: 0.9542
  Class 1: 0.6937
  Class 2: 0.8512
  Class 3: 0.2475
  Class 4: 0.4075
  Class 5: 0.2559
  Class 6: 0.4268
  Class 7: 0.5195
  Class 8: 0.8607
  Class 9: 0.4946
  Class 10: 0.8756
  Class 11: 0.6056
  Class 12: 0.3945
  Class 13: 0.8526
  Class 14: 0.4244
  Class 15: 0.5281
  Class 16: 0.1337
  Class 17: 0.2990
  Class 18: 0.5789

Training Losses:
  Epoch 1: 0.396987
  Epoch 2: 0.333643
  Epoch 3: 0.330101
  Epoch 4: 0.269141
  Epoch 5: 0.228650

Validation Losses:
  Epoch 1: 0.358211
  Epoch 2: 0.361618
  Epoch 3: 0.345302
  Epoch 4: 0.296206
  Epoch 5: 0.261598

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6198

Per-Class IoU:
  Class 0: 0.9591
  Class 1: 0.7235
  Class 2: 0.8673
  Class 3: 0.4360
  Class 4: 0.4884
  Class 5: 0.2994
  Class 6: 0.4693
  Class 7: 0.5522
  Class 8: 0.8728
  Class 9: 0.5491
  Class 10: 0.8818
  Class 11: 0.6331
  Class 12: 0.4321
  Class 13: 0.8670
  Class 14: 0.6303
  Class 15: 0.6813
  Class 16: 0.4193
  Class 17: 0.4040
  Class 18: 0.6108

Training Losses:
  Epoch 1: 0.190700
  Epoch 2: 0.189885
  Epoch 3: 0.185133
  Epoch 4: 0.176632
  Epoch 5: 0.171795

Validation Losses:
  Epoch 1: 0.233594
  Epoch 2: 0.230059
  Epoch 3: 0.227277
  Epoch 4: 0.224445
  Epoch 5: 0.226580

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.0001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

