Model Size: 10.57 MB

mIoU: 0.5789

Per-Class IoU:
  Class 0: 0.9570
  Class 1: 0.7094
  Class 2: 0.8565
  Class 3: 0.3360
  Class 4: 0.4539
  Class 5: 0.2725
  Class 6: 0.4575
  Class 7: 0.5289
  Class 8: 0.8695
  Class 9: 0.5419
  Class 10: 0.8754
  Class 11: 0.6112
  Class 12: 0.4157
  Class 13: 0.8610
  Class 14: 0.4424
  Class 15: 0.5857
  Class 16: 0.2672
  Class 17: 0.3637
  Class 18: 0.5934

Training Losses:
  Epoch 1: 0.372000
  Epoch 2: 0.310982
  Epoch 3: 0.285639
  Epoch 4: 0.241414
  Epoch 5: 0.210234

Validation Losses:
  Epoch 1: 0.335672
  Epoch 2: 0.511809
  Epoch 3: 0.315458
  Epoch 4: 0.274149
  Epoch 5: 0.242905

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.5476

Per-Class IoU:
  Class 0: 0.9542
  Class 1: 0.6937
  Class 2: 0.8512
  Class 3: 0.2475
  Class 4: 0.4075
  Class 5: 0.2559
  Class 6: 0.4268
  Class 7: 0.5195
  Class 8: 0.8607
  Class 9: 0.4946
  Class 10: 0.8756
  Class 11: 0.6056
  Class 12: 0.3945
  Class 13: 0.8526
  Class 14: 0.4244
  Class 15: 0.5281
  Class 16: 0.1337
  Class 17: 0.2990
  Class 18: 0.5789

Training Losses:
  Epoch 1: 0.396987
  Epoch 2: 0.333643
  Epoch 3: 0.330101
  Epoch 4: 0.269141
  Epoch 5: 0.228650

Validation Losses:
  Epoch 1: 0.358211
  Epoch 2: 0.361618
  Epoch 3: 0.345302
  Epoch 4: 0.296206
  Epoch 5: 0.261598

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6198

Per-Class IoU:
  Class 0: 0.9591
  Class 1: 0.7235
  Class 2: 0.8673
  Class 3: 0.4360
  Class 4: 0.4884
  Class 5: 0.2994
  Class 6: 0.4693
  Class 7: 0.5522
  Class 8: 0.8728
  Class 9: 0.5491
  Class 10: 0.8818
  Class 11: 0.6331
  Class 12: 0.4321
  Class 13: 0.8670
  Class 14: 0.6303
  Class 15: 0.6813
  Class 16: 0.4193
  Class 17: 0.4040
  Class 18: 0.6108

Training Losses:
  Epoch 1: 0.190700
  Epoch 2: 0.189885
  Epoch 3: 0.185133
  Epoch 4: 0.176632
  Epoch 5: 0.171795

Validation Losses:
  Epoch 1: 0.233594
  Epoch 2: 0.230059
  Epoch 3: 0.227277
  Epoch 4: 0.224445
  Epoch 5: 0.226580

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.0001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6189

Per-Class IoU:
  Class 0: 0.9588
  Class 1: 0.7220
  Class 2: 0.8671
  Class 3: 0.4362
  Class 4: 0.4831
  Class 5: 0.2986
  Class 6: 0.4672
  Class 7: 0.5520
  Class 8: 0.8727
  Class 9: 0.5485
  Class 10: 0.8807
  Class 11: 0.6336
  Class 12: 0.4320
  Class 13: 0.8673
  Class 14: 0.6335
  Class 15: 0.6808
  Class 16: 0.4149
  Class 17: 0.4000
  Class 18: 0.6109

Training Losses:
  Epoch 1: 0.191646
  Epoch 2: 0.191826
  Epoch 3: 0.187721
  Epoch 4: 0.179249
  Epoch 5: 0.173725

Validation Losses:
  Epoch 1: 0.232752
  Epoch 2: 0.230095
  Epoch 3: 0.230232
  Epoch 4: 0.225554
  Epoch 5: 0.226934

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.0001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6095

Per-Class IoU:
  Class 0: 0.9580
  Class 1: 0.7149
  Class 2: 0.8635
  Class 3: 0.3906
  Class 4: 0.4658
  Class 5: 0.2886
  Class 6: 0.4654
  Class 7: 0.5455
  Class 8: 0.8729
  Class 9: 0.5495
  Class 10: 0.8810
  Class 11: 0.6227
  Class 12: 0.4373
  Class 13: 0.8639
  Class 14: 0.6057
  Class 15: 0.6669
  Class 16: 0.3764
  Class 17: 0.4062
  Class 18: 0.6059

Training Losses:
  Epoch 1: 0.279794
  Epoch 2: 0.254577
  Epoch 3: 0.230803
  Epoch 4: 0.213778
  Epoch 5: 0.189248

Validation Losses:
  Epoch 1: 0.260523
  Epoch 2: 0.261365
  Epoch 3: 0.413172
  Epoch 4: 0.249159
  Epoch 5: 0.233534

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.0005
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.5968

Per-Class IoU:
  Class 0: 0.9568
  Class 1: 0.7133
  Class 2: 0.8610
  Class 3: 0.3731
  Class 4: 0.4514
  Class 5: 0.2772
  Class 6: 0.4511
  Class 7: 0.5451
  Class 8: 0.8722
  Class 9: 0.5416
  Class 10: 0.8790
  Class 11: 0.6234
  Class 12: 0.4218
  Class 13: 0.8620
  Class 14: 0.5630
  Class 15: 0.6614
  Class 16: 0.3184
  Class 17: 0.3656
  Class 18: 0.6012

Training Losses:
  Epoch 1: 0.287950
  Epoch 2: 0.268244
  Epoch 3: 0.257028
  Epoch 4: 0.224480
  Epoch 5: 0.200724

Validation Losses:
  Epoch 1: 0.270965
  Epoch 2: 0.325308
  Epoch 3: 0.295167
  Epoch 4: 0.278435
  Epoch 5: 0.236744

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.0005
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.5990

Per-Class IoU:
  Class 0: 0.9563
  Class 1: 0.7093
  Class 2: 0.8595
  Class 3: 0.3242
  Class 4: 0.4767
  Class 5: 0.3028
  Class 6: 0.4572
  Class 7: 0.5399
  Class 8: 0.8687
  Class 9: 0.5311
  Class 10: 0.8486
  Class 11: 0.6267
  Class 12: 0.4402
  Class 13: 0.8580
  Class 14: 0.5462
  Class 15: 0.6373
  Class 16: 0.4278
  Class 17: 0.3665
  Class 18: 0.6038

Training Losses:
  Epoch 1: 0.307537
  Epoch 2: 0.269714
  Epoch 3: 0.234271
  Epoch 4: 0.220300
  Epoch 5: 0.194594

Validation Losses:
  Epoch 1: 0.308014
  Epoch 2: 0.306219
  Epoch 3: 0.354610
  Epoch 4: 0.240219
  Epoch 5: 0.239666

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.5886

Per-Class IoU:
  Class 0: 0.9561
  Class 1: 0.7039
  Class 2: 0.8584
  Class 3: 0.2711
  Class 4: 0.4680
  Class 5: 0.2859
  Class 6: 0.4418
  Class 7: 0.5244
  Class 8: 0.8667
  Class 9: 0.5279
  Class 10: 0.8771
  Class 11: 0.6246
  Class 12: 0.4293
  Class 13: 0.8570
  Class 14: 0.5562
  Class 15: 0.6210
  Class 16: 0.3741
  Class 17: 0.3410
  Class 18: 0.5985

Training Losses:
  Epoch 1: 0.318677
  Epoch 2: 0.299879
  Epoch 3: 0.265600
  Epoch 4: 0.239628
  Epoch 5: 0.209777

Validation Losses:
  Epoch 1: 0.316513
  Epoch 2: 0.324697
  Epoch 3: 0.352329
  Epoch 4: 0.257345
  Epoch 5: 0.239433

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6280

Per-Class IoU:
  Class 0: 0.9578
  Class 1: 0.7159
  Class 2: 0.8682
  Class 3: 0.4503
  Class 4: 0.4971
  Class 5: 0.3030
  Class 6: 0.4697
  Class 7: 0.5536
  Class 8: 0.8711
  Class 9: 0.5437
  Class 10: 0.8874
  Class 11: 0.6341
  Class 12: 0.4351
  Class 13: 0.8649
  Class 14: 0.6506
  Class 15: 0.6918
  Class 16: 0.5087
  Class 17: 0.4221
  Class 18: 0.6072

Training Losses:
  Epoch 1: 0.176067
  Epoch 2: 0.178925
  Epoch 3: 0.169333
  Epoch 4: 0.166668
  Epoch 5: 0.165722

Validation Losses:
  Epoch 1: 0.233456
  Epoch 2: 0.225800
  Epoch 3: 0.221923
  Epoch 4: 0.225160
  Epoch 5: 0.227659

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.0001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6277

Per-Class IoU:
  Class 0: 0.9578
  Class 1: 0.7155
  Class 2: 0.8686
  Class 3: 0.4519
  Class 4: 0.4984
  Class 5: 0.3043
  Class 6: 0.4677
  Class 7: 0.5529
  Class 8: 0.8714
  Class 9: 0.5428
  Class 10: 0.8875
  Class 11: 0.6353
  Class 12: 0.4357
  Class 13: 0.8657
  Class 14: 0.6583
  Class 15: 0.6888
  Class 16: 0.4953
  Class 17: 0.4208
  Class 18: 0.6076

Training Losses:
  Epoch 1: 0.176579
  Epoch 2: 0.180496
  Epoch 3: 0.170884
  Epoch 4: 0.168535
  Epoch 5: 0.167365

Validation Losses:
  Epoch 1: 0.231391
  Epoch 2: 0.224433
  Epoch 3: 0.220731
  Epoch 4: 0.223998
  Epoch 5: 0.226713

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.0001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6262

Per-Class IoU:
  Class 0: 0.9569
  Class 1: 0.7128
  Class 2: 0.8688
  Class 3: 0.4663
  Class 4: 0.4922
  Class 5: 0.3001
  Class 6: 0.4641
  Class 7: 0.5408
  Class 8: 0.8701
  Class 9: 0.5314
  Class 10: 0.8874
  Class 11: 0.6314
  Class 12: 0.4365
  Class 13: 0.8648
  Class 14: 0.6266
  Class 15: 0.6797
  Class 16: 0.5293
  Class 17: 0.4308
  Class 18: 0.6077

Training Losses:
  Epoch 1: 0.232658
  Epoch 2: 0.231141
  Epoch 3: 0.200530
  Epoch 4: 0.194209
  Epoch 5: 0.178884

Validation Losses:
  Epoch 1: 0.274969
  Epoch 2: 0.262263
  Epoch 3: 0.256083
  Epoch 4: 0.230848
  Epoch 5: 0.230093

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.0005
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6182

Per-Class IoU:
  Class 0: 0.9559
  Class 1: 0.7081
  Class 2: 0.8644
  Class 3: 0.3831
  Class 4: 0.4870
  Class 5: 0.3014
  Class 6: 0.4586
  Class 7: 0.5346
  Class 8: 0.8679
  Class 9: 0.5192
  Class 10: 0.8823
  Class 11: 0.6300
  Class 12: 0.4347
  Class 13: 0.8602
  Class 14: 0.5934
  Class 15: 0.6802
  Class 16: 0.5684
  Class 17: 0.4097
  Class 18: 0.6068

Training Losses:
  Epoch 1: 0.237695
  Epoch 2: 0.241863
  Epoch 3: 0.215564
  Epoch 4: 0.207520
  Epoch 5: 0.187546

Validation Losses:
  Epoch 1: 0.270920
  Epoch 2: 0.262957
  Epoch 3: 0.304762
  Epoch 4: 0.233029
  Epoch 5: 0.233219

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.0005
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6044

Per-Class IoU:
  Class 0: 0.9581
  Class 1: 0.7116
  Class 2: 0.8622
  Class 3: 0.3820
  Class 4: 0.4555
  Class 5: 0.3097
  Class 6: 0.4654
  Class 7: 0.5423
  Class 8: 0.8696
  Class 9: 0.5169
  Class 10: 0.8840
  Class 11: 0.6276
  Class 12: 0.4103
  Class 13: 0.8581
  Class 14: 0.6110
  Class 15: 0.6414
  Class 16: 0.3729
  Class 17: 0.3993
  Class 18: 0.6052

Training Losses:
  Epoch 1: 0.261727
  Epoch 2: 0.242457
  Epoch 3: 0.216216
  Epoch 4: 0.197208
  Epoch 5: 0.180843

Validation Losses:
  Epoch 1: 0.315174
  Epoch 2: 0.263152
  Epoch 3: 0.239423
  Epoch 4: 0.235571
  Epoch 5: 0.230374

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 16
  learning_rate: 0.001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.5950

Per-Class IoU:
  Class 0: 0.9570
  Class 1: 0.7102
  Class 2: 0.8597
  Class 3: 0.3697
  Class 4: 0.4320
  Class 5: 0.3002
  Class 6: 0.4457
  Class 7: 0.5312
  Class 8: 0.8691
  Class 9: 0.4968
  Class 10: 0.8829
  Class 11: 0.6335
  Class 12: 0.4093
  Class 13: 0.8562
  Class 14: 0.5494
  Class 15: 0.6221
  Class 16: 0.3853
  Class 17: 0.3902
  Class 18: 0.6043

Training Losses:
  Epoch 1: 0.271845
  Epoch 2: 0.249970
  Epoch 3: 0.238702
  Epoch 4: 0.214254
  Epoch 5: 0.191270

Validation Losses:
  Epoch 1: 0.343243
  Epoch 2: 0.302148
  Epoch 3: 0.297706
  Epoch 4: 0.243271
  Epoch 5: 0.232063

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 16
  learning_rate: 0.001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6177

Per-Class IoU:
  Class 0: 0.9589
  Class 1: 0.7202
  Class 2: 0.8688
  Class 3: 0.4698
  Class 4: 0.4897
  Class 5: 0.3084
  Class 6: 0.4705
  Class 7: 0.5537
  Class 8: 0.8729
  Class 9: 0.5384
  Class 10: 0.8846
  Class 11: 0.6341
  Class 12: 0.4302
  Class 13: 0.8632
  Class 14: 0.6102
  Class 15: 0.6579
  Class 16: 0.3889
  Class 17: 0.4083
  Class 18: 0.6071

Training Losses:
  Epoch 1: 0.171567
  Epoch 2: 0.169762
  Epoch 3: 0.162966
  Epoch 4: 0.162505
  Epoch 5: 0.159112

Validation Losses:
  Epoch 1: 0.231261
  Epoch 2: 0.222312
  Epoch 3: 0.223401
  Epoch 4: 0.224567
  Epoch 5: 0.225303

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 16
  learning_rate: 0.0001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6162

Per-Class IoU:
  Class 0: 0.9589
  Class 1: 0.7203
  Class 2: 0.8690
  Class 3: 0.4707
  Class 4: 0.4870
  Class 5: 0.3101
  Class 6: 0.4690
  Class 7: 0.5543
  Class 8: 0.8731
  Class 9: 0.5361
  Class 10: 0.8849
  Class 11: 0.6349
  Class 12: 0.4292
  Class 13: 0.8635
  Class 14: 0.6069
  Class 15: 0.6557
  Class 16: 0.3696
  Class 17: 0.4073
  Class 18: 0.6079

Training Losses:
  Epoch 1: 0.171819
  Epoch 2: 0.170428
  Epoch 3: 0.163800
  Epoch 4: 0.163465
  Epoch 5: 0.159997

Validation Losses:
  Epoch 1: 0.230043
  Epoch 2: 0.220038
  Epoch 3: 0.221372
  Epoch 4: 0.223047
  Epoch 5: 0.224176

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 16
  learning_rate: 0.0001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6135

Per-Class IoU:
  Class 0: 0.9586
  Class 1: 0.7176
  Class 2: 0.8669
  Class 3: 0.4652
  Class 4: 0.4740
  Class 5: 0.3095
  Class 6: 0.4694
  Class 7: 0.5534
  Class 8: 0.8712
  Class 9: 0.5352
  Class 10: 0.8840
  Class 11: 0.6324
  Class 12: 0.4268
  Class 13: 0.8594
  Class 14: 0.5918
  Class 15: 0.6590
  Class 16: 0.3603
  Class 17: 0.4165
  Class 18: 0.6052

Training Losses:
  Epoch 1: 0.209208
  Epoch 2: 0.201317
  Epoch 3: 0.181244
  Epoch 4: 0.177713
  Epoch 5: 0.167256

Validation Losses:
  Epoch 1: 0.278586
  Epoch 2: 0.234455
  Epoch 3: 0.228438
  Epoch 4: 0.232839
  Epoch 5: 0.225159

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 16
  learning_rate: 0.0005
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 10.57 MB

mIoU: 0.6109

Per-Class IoU:
  Class 0: 0.9583
  Class 1: 0.7168
  Class 2: 0.8653
  Class 3: 0.4372
  Class 4: 0.4536
  Class 5: 0.3109
  Class 6: 0.4616
  Class 7: 0.5523
  Class 8: 0.8708
  Class 9: 0.5228
  Class 10: 0.8848
  Class 11: 0.6342
  Class 12: 0.4111
  Class 13: 0.8595
  Class 14: 0.5954
  Class 15: 0.6641
  Class 16: 0.4049
  Class 17: 0.3958
  Class 18: 0.6071

Training Losses:
  Epoch 1: 0.212085
  Epoch 2: 0.207867
  Epoch 3: 0.192647
  Epoch 4: 0.188400
  Epoch 5: 0.174213

Validation Losses:
  Epoch 1: 0.275439
  Epoch 2: 0.237435
  Epoch 3: 0.245064
  Epoch 4: 0.230393
  Epoch 5: 0.224427

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: histogram
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 16
  learning_rate: 0.0005
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 9.66 MB

mIoU: 0.5794

Per-Class IoU:
  Class 0: 0.9581
  Class 1: 0.7145
  Class 2: 0.8596
  Class 3: 0.3351
  Class 4: 0.4426
  Class 5: 0.2778
  Class 6: 0.4525
  Class 7: 0.5328
  Class 8: 0.8690
  Class 9: 0.5412
  Class 10: 0.8813
  Class 11: 0.6134
  Class 12: 0.4192
  Class 13: 0.8609
  Class 14: 0.4929
  Class 15: 0.6017
  Class 16: 0.1915
  Class 17: 0.3745
  Class 18: 0.5900

Training Losses:
  Epoch 1: 0.372929
  Epoch 2: 0.306390
  Epoch 3: 0.282022
  Epoch 4: 0.240241
  Epoch 5: 0.207632

Validation Losses:
  Epoch 1: 0.310701
  Epoch 2: 0.409933
  Epoch 3: 0.346940
  Epoch 4: 0.268248
  Epoch 5: 0.242486

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: minmax
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 9.66 MB

mIoU: 0.5511

Per-Class IoU:
  Class 0: 0.9535
  Class 1: 0.6928
  Class 2: 0.8544
  Class 3: 0.2498
  Class 4: 0.4299
  Class 5: 0.2537
  Class 6: 0.4361
  Class 7: 0.5220
  Class 8: 0.8622
  Class 9: 0.5121
  Class 10: 0.8715
  Class 11: 0.6046
  Class 12: 0.3885
  Class 13: 0.8531
  Class 14: 0.4164
  Class 15: 0.5014
  Class 16: 0.1587
  Class 17: 0.3279
  Class 18: 0.5830

Training Losses:
  Epoch 1: 0.392264
  Epoch 2: 0.341102
  Epoch 3: 0.319259
  Epoch 4: 0.266174
  Epoch 5: 0.226945

Validation Losses:
  Epoch 1: 0.344675
  Epoch 2: 0.786804
  Epoch 3: 0.355281
  Epoch 4: 0.298719
  Epoch 5: 0.259076

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: minmax
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 9.66 MB

mIoU: 0.6202

Per-Class IoU:
  Class 0: 0.9591
  Class 1: 0.7239
  Class 2: 0.8677
  Class 3: 0.4379
  Class 4: 0.4877
  Class 5: 0.2992
  Class 6: 0.4690
  Class 7: 0.5523
  Class 8: 0.8727
  Class 9: 0.5502
  Class 10: 0.8821
  Class 11: 0.6328
  Class 12: 0.4319
  Class 13: 0.8673
  Class 14: 0.6354
  Class 15: 0.6817
  Class 16: 0.4161
  Class 17: 0.4048
  Class 18: 0.6111

Training Losses:
  Epoch 1: 0.190796
  Epoch 2: 0.189943
  Epoch 3: 0.185044
  Epoch 4: 0.176699
  Epoch 5: 0.171798

Validation Losses:
  Epoch 1: 0.234440
  Epoch 2: 0.229586
  Epoch 3: 0.227300
  Epoch 4: 0.223855
  Epoch 5: 0.226242

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: minmax
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.0001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 9.66 MB

mIoU: 0.6191

Per-Class IoU:
  Class 0: 0.9590
  Class 1: 0.7228
  Class 2: 0.8667
  Class 3: 0.4253
  Class 4: 0.4830
  Class 5: 0.2994
  Class 6: 0.4679
  Class 7: 0.5526
  Class 8: 0.8727
  Class 9: 0.5498
  Class 10: 0.8804
  Class 11: 0.6342
  Class 12: 0.4340
  Class 13: 0.8678
  Class 14: 0.6356
  Class 15: 0.6807
  Class 16: 0.4131
  Class 17: 0.4069
  Class 18: 0.6107

Training Losses:
  Epoch 1: 0.191638
  Epoch 2: 0.191997
  Epoch 3: 0.187419
  Epoch 4: 0.179090
  Epoch 5: 0.173870

Validation Losses:
  Epoch 1: 0.233286
  Epoch 2: 0.230013
  Epoch 3: 0.229591
  Epoch 4: 0.225918
  Epoch 5: 0.227215

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: minmax
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.0001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 9.66 MB

mIoU: 0.6032

Per-Class IoU:
  Class 0: 0.9578
  Class 1: 0.7141
  Class 2: 0.8641
  Class 3: 0.4186
  Class 4: 0.4658
  Class 5: 0.2855
  Class 6: 0.4651
  Class 7: 0.5447
  Class 8: 0.8726
  Class 9: 0.5395
  Class 10: 0.8810
  Class 11: 0.6218
  Class 12: 0.4334
  Class 13: 0.8642
  Class 14: 0.5912
  Class 15: 0.6477
  Class 16: 0.2879
  Class 17: 0.4000
  Class 18: 0.6053

Training Losses:
  Epoch 1: 0.277507
  Epoch 2: 0.251394
  Epoch 3: 0.232198
  Epoch 4: 0.211048
  Epoch 5: 0.189187

Validation Losses:
  Epoch 1: 0.257748
  Epoch 2: 0.271794
  Epoch 3: 0.285380
  Epoch 4: 0.249083
  Epoch 5: 0.233779

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: minmax
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.0005
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 9.66 MB

mIoU: 0.6023

Per-Class IoU:
  Class 0: 0.9570
  Class 1: 0.7118
  Class 2: 0.8606
  Class 3: 0.3815
  Class 4: 0.4592
  Class 5: 0.2764
  Class 6: 0.4557
  Class 7: 0.5403
  Class 8: 0.8720
  Class 9: 0.5459
  Class 10: 0.8801
  Class 11: 0.6220
  Class 12: 0.4240
  Class 13: 0.8637
  Class 14: 0.5660
  Class 15: 0.6627
  Class 16: 0.3745
  Class 17: 0.3869
  Class 18: 0.6026

Training Losses:
  Epoch 1: 0.287999
  Epoch 2: 0.267699
  Epoch 3: 0.246586
  Epoch 4: 0.224897
  Epoch 5: 0.199340

Validation Losses:
  Epoch 1: 0.265596
  Epoch 2: 0.303465
  Epoch 3: 0.312473
  Epoch 4: 0.264137
  Epoch 5: 0.237166

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: minmax
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 4
  learning_rate: 0.0005
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 9.66 MB

mIoU: 0.6087

Per-Class IoU:
  Class 0: 0.9563
  Class 1: 0.7111
  Class 2: 0.8647
  Class 3: 0.3521
  Class 4: 0.4806
  Class 5: 0.3022
  Class 6: 0.4547
  Class 7: 0.5367
  Class 8: 0.8692
  Class 9: 0.5311
  Class 10: 0.8829
  Class 11: 0.6280
  Class 12: 0.4299
  Class 13: 0.8652
  Class 14: 0.5723
  Class 15: 0.6432
  Class 16: 0.4767
  Class 17: 0.4019
  Class 18: 0.6063

Training Losses:
  Epoch 1: 0.310586
  Epoch 2: 0.266758
  Epoch 3: 0.242932
  Epoch 4: 0.218550
  Epoch 5: 0.194622

Validation Losses:
  Epoch 1: 0.310002
  Epoch 2: 0.284061
  Epoch 3: 0.272596
  Epoch 4: 0.235343
  Epoch 5: 0.233525

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: minmax
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 9.66 MB

mIoU: 0.5889

Per-Class IoU:
  Class 0: 0.9560
  Class 1: 0.7043
  Class 2: 0.8595
  Class 3: 0.2635
  Class 4: 0.4680
  Class 5: 0.2874
  Class 6: 0.4248
  Class 7: 0.5229
  Class 8: 0.8650
  Class 9: 0.5262
  Class 10: 0.8765
  Class 11: 0.6247
  Class 12: 0.4304
  Class 13: 0.8599
  Class 14: 0.5529
  Class 15: 0.6189
  Class 16: 0.3958
  Class 17: 0.3554
  Class 18: 0.5969

Training Losses:
  Epoch 1: 0.326943
  Epoch 2: 0.293140
  Epoch 3: 0.263355
  Epoch 4: 0.235664
  Epoch 5: 0.208714

Validation Losses:
  Epoch 1: 0.314534
  Epoch 2: 0.314246
  Epoch 3: 0.345421
  Epoch 4: 0.251560
  Epoch 5: 0.240882

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: minmax
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 9.66 MB

mIoU: 0.6282

Per-Class IoU:
  Class 0: 0.9577
  Class 1: 0.7158
  Class 2: 0.8682
  Class 3: 0.4514
  Class 4: 0.4972
  Class 5: 0.3030
  Class 6: 0.4700
  Class 7: 0.5537
  Class 8: 0.8711
  Class 9: 0.5433
  Class 10: 0.8874
  Class 11: 0.6341
  Class 12: 0.4351
  Class 13: 0.8649
  Class 14: 0.6509
  Class 15: 0.6919
  Class 16: 0.5099
  Class 17: 0.4222
  Class 18: 0.6072

Training Losses:
  Epoch 1: 0.176069
  Epoch 2: 0.178919
  Epoch 3: 0.169326
  Epoch 4: 0.166668
  Epoch 5: 0.165732

Validation Losses:
  Epoch 1: 0.233546
  Epoch 2: 0.225851
  Epoch 3: 0.221921
  Epoch 4: 0.225190
  Epoch 5: 0.227634

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: minmax
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.0001
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 9.66 MB

mIoU: 0.6279

Per-Class IoU:
  Class 0: 0.9578
  Class 1: 0.7157
  Class 2: 0.8687
  Class 3: 0.4523
  Class 4: 0.4988
  Class 5: 0.3044
  Class 6: 0.4678
  Class 7: 0.5530
  Class 8: 0.8714
  Class 9: 0.5429
  Class 10: 0.8875
  Class 11: 0.6353
  Class 12: 0.4361
  Class 13: 0.8658
  Class 14: 0.6587
  Class 15: 0.6888
  Class 16: 0.4966
  Class 17: 0.4210
  Class 18: 0.6076

Training Losses:
  Epoch 1: 0.176578
  Epoch 2: 0.180509
  Epoch 3: 0.170890
  Epoch 4: 0.168525
  Epoch 5: 0.167363

Validation Losses:
  Epoch 1: 0.231464
  Epoch 2: 0.224394
  Epoch 3: 0.220631
  Epoch 4: 0.223894
  Epoch 5: 0.226597

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: minmax
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.0001
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 9.66 MB

mIoU: 0.6250

Per-Class IoU:
  Class 0: 0.9570
  Class 1: 0.7125
  Class 2: 0.8686
  Class 3: 0.4647
  Class 4: 0.4946
  Class 5: 0.3010
  Class 6: 0.4640
  Class 7: 0.5413
  Class 8: 0.8697
  Class 9: 0.5279
  Class 10: 0.8875
  Class 11: 0.6316
  Class 12: 0.4341
  Class 13: 0.8645
  Class 14: 0.6122
  Class 15: 0.6777
  Class 16: 0.5326
  Class 17: 0.4265
  Class 18: 0.6067

Training Losses:
  Epoch 1: 0.233196
  Epoch 2: 0.231299
  Epoch 3: 0.200315
  Epoch 4: 0.194744
  Epoch 5: 0.179160

Validation Losses:
  Epoch 1: 0.278925
  Epoch 2: 0.257350
  Epoch 3: 0.252979
  Epoch 4: 0.230442
  Epoch 5: 0.230632

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: minmax
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.0005
  weight_decay: 1.0e-05
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

Model Size: 9.66 MB

mIoU: 0.6183

Per-Class IoU:
  Class 0: 0.9568
  Class 1: 0.7114
  Class 2: 0.8654
  Class 3: 0.4211
  Class 4: 0.4914
  Class 5: 0.3044
  Class 6: 0.4567
  Class 7: 0.5382
  Class 8: 0.8697
  Class 9: 0.5234
  Class 10: 0.8836
  Class 11: 0.6322
  Class 12: 0.4317
  Class 13: 0.8631
  Class 14: 0.5918
  Class 15: 0.6712
  Class 16: 0.5095
  Class 17: 0.4165
  Class 18: 0.6099

Training Losses:
  Epoch 1: 0.236266
  Epoch 2: 0.244981
  Epoch 3: 0.213553
  Epoch 4: 0.204706
  Epoch 5: 0.186716

Validation Losses:
  Epoch 1: 0.264367
  Epoch 2: 0.260864
  Epoch 3: 0.263116
  Epoch 4: 0.234112
  Epoch 5: 0.229908

Bit Depth Distribution:
  8-bit layers: 47
  6-bit layers: 47
  4-bit layers: 93

Configuration Parameters:
model_checkpoint: models/baseline_init_model.pth
mode: int8
weights:
  dtype: qint8
  granularity: per_channel
activations:
  dtype: quint8
  granularity: per_tensor
  observer: minmax
calibration:
  enabled: true
  steps: 128
training:
  epochs: 5
  batch_size: 8
  learning_rate: 0.0005
  weight_decay: 0.0001
  train_transforms:
    crop: true
    resize: true
    flip: true
  val_transforms:
    crop: false
    resize: false
    flip: false
skip_aspp: true

============================================================

